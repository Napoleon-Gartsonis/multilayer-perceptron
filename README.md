# multilayer-perceptron

## Project summary

A multilayer perceptron implemented using python from scratch. 

## Features implemented so far are:

- variable size of hidden layers
- variable size of neurons per layer
- learning rate
- activation functions: relu, sigmoid
- weight initialization: random, he and xavier
- variable number of training epochs
- random state for debugging

## Future features:

- batch training
- different cost functions
- learning rate adjustment during training
- gradient descent with momentum
- regularization  